{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "In this notebook we are going to implement the gradient descent function. For the implementation we need an activation and a cost function. We will use Sigmoid as activation function and log loss as the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def sigmoid_numpy(X):\n",
    "   return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log loss cost function\n",
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent \n",
    "def gradient_descent(x1, x2, y_true, epochs, loss_threshold):\n",
    "    w1 = w2 = 0\n",
    "    bias = 0\n",
    "    rate = 0.5  # learning rate\n",
    "    n = len(x1)\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1 * x1 + w2 * x2 + bias\n",
    "        y_predicted = sigmoid_numpy(weighted_sum)\n",
    "        loss = log_loss(y_true, y_predicted)\n",
    "        \n",
    "        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true)) \n",
    "        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true))\n",
    "        biasd = np.mean(y_predicted - y_true)\n",
    "        \n",
    "        # update w1, w2 and bias\n",
    "        w1 = w1 - rate * w1d\n",
    "        w2 = w2 - rate * w2d\n",
    "        bias = bias - rate * biasd\n",
    "        \n",
    "        print(f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias} loss:{loss}')\n",
    "        \n",
    "        #stop when loss reaches a threshold\n",
    "        if loss <= loss_threshold:\n",
    "            break\n",
    "    return w1, w2, bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
